{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from from_scratch.neural_network import Neural_network\n",
    "from from_scratch.hidden_layer import Layer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output_layer_MSE(Layer):\n",
    "    def __innit__(self, n_neurons:int, nprev_neurons:int, learning_rate:float, activation_function:str):\n",
    "        super().__init__(n_neurons, nprev_neurons, learning_rate, activation_function)\n",
    "    \n",
    "    def calculate_error_term(self, target):\n",
    "        self.error_term = (target - self.node_output) / self.n_neurons\n",
    "        for i in range(self.n_neurons):\n",
    "            self.error_term[0][i] *= self.activation_derivative(self.node_value[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataq2.csv')\n",
    "y = data['y']\n",
    "X = data.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.array(X)\n",
    "x_train = X_[round(len(X_)*0.8):]\n",
    "x_test = X_[:round(len(X_)*0.2)]\n",
    "y_ = np.array(y)\n",
    "y_train = y_[round(len(y_)*0.8):]\n",
    "y_test = y_[:round(len(y_)*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Neural_network(layer_list=[Layer(2,2,0.01, 'relu'), \n",
    "                                Layer(2,2,0.01, 'relu'),\n",
    "                                Output_layer_MSE(1,2, 0.01, 'sigmoid')])\n",
    "\n",
    "nn.train(x_train, y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80990477]]\n",
      "[[0.805469]]\n",
      "[[0.78848779]]\n",
      "[[0.76574652]]\n",
      "[[0.74066351]]\n",
      "[[0.71794033]]\n",
      "[[0.70673021]]\n",
      "[[0.70955195]]\n",
      "[[0.71946567]]\n",
      "[[0.73084735]]\n",
      "[[0.76290468]]\n",
      "[[0.79158537]]\n",
      "[[0.81700346]]\n",
      "[[0.82523056]]\n"
     ]
    }
   ],
   "source": [
    "# has its possible to percieve on this result and the mean square error,\n",
    "# the neural network has some fail of design !!! its giving always 1 and getting write 50% of the time.... \n",
    "for i in range(len(x_test)):    \n",
    "    print(nn.predict(x_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32122340682942535"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.mean_square_error(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but lets test if giving a proper treatment to the data, it may solve our problem .... \\\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X1_train_scaled = np.array(scaler.fit_transform(X1_train))\n",
    "X1_test_scaled = scaler.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train_scaled = np.array(X1_train_scaled)\n",
    "X1_test_scaled = np.array(X1_test_scaled)\n",
    "\n",
    "y1_train = np.array(y1_train)\n",
    "y1_test = np.array(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1 = Neural_network(layer_list=[Layer(2,2,0.01, 'relu'), \n",
    "                                Layer(4,2,0.01, 'relu'),\n",
    "                                Layer(4,4,0.01, 'relu'),\n",
    "                                Output_layer_MSE(1,4, 0.01, 'sigmoid')])\n",
    "\n",
    "nn1.train(X1_train_scaled , y1_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72728845 -1.44116206]\n",
      "[[0.55143137]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-0.63073669  1.60950847]\n",
      "[[0.54904421]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-1.16458105  1.56669204]\n",
      "[[0.55755444]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-0.64010237 -0.26371027]\n",
      "[[0.55182032]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-0.05942956  0.83881276]\n",
      "[[0.54423394]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[ 1.42034954 -0.61694581]\n",
      "[[0.53176824]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[ 0.25900392 -0.26371027]\n",
      "[[0.54511544]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-1.33316349  0.17515812]\n",
      "[[0.55633605]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-1.07092415  0.9137415 ]\n",
      "[[0.55954313]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[0.48378049 0.98867025]\n",
      "[[0.53496589]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-0.94917016  1.37401811]\n",
      "[[0.5552319]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-0.27484045 -0.72398688]\n",
      "[[0.55055882]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[0.22154115 0.81740454]\n",
      "[[0.5399684]]\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "[-0.79931913 -0.91666081]\n",
      "[[0.55114133]]\n",
      "--------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As you can notice, even when randomly picking from a more standardized distribution and properly fitting the data to train, the same result is achieved.\n",
    "for i in range(len(X1_test_scaled)):\n",
    "    print(X1_test_scaled[i])\n",
    "    print(nn1.predict(np.array(X1_test_scaled)[i]))\n",
    "    print('--------------------------------------')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "for i in range(len(X1_test_scaled)):\n",
    "    L.append(round(nn1.predict(np.array(X1_test_scaled[i]))[0][0]) == y1_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(L.count(True)/len(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25241507562971843"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.mean_square_error(X1_test_scaled, y1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
